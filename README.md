# 🚀 etx-delivery-labs

Welcome to the **ETX Delivery Labs** — a hands-on workshop introducing Artificial Intelligence (AI) concepts and tools within the **Red Hat ecosystem**.

This workshop is designed for developers, architects, and operations teams looking to explore how AI can be integrated with Red Hat technologies such as **OpenShift**, **RHEL AI**, **Podman**, and more.

---

## 📚 What You'll Learn

- The fundamentals of AI/ML practices in enterprise environments
- How to containerize and serve AI models using Podman and OpenShift
- Prompt engineering techniques to get the best from large language models (LLMs)
- Building and evaluating AI pipelines using tools like Ollama, Docling, and HuggingFace
- Guardrails and best practices for responsible AI usage

---

## 🧰 Prerequisites

Before you begin, make sure you’ve completed all setup steps outlined in the  
👉 [Prerequisites Section](workshop/content/prereqs.md)

---

## 🧭 Getting Started

Start the workshop by clicking below:

👉 [Begin the Workshop](workshop/content/index.md)

---

## 🏗️ Structure

The workshop is broken into several self-contained modules:
- **InstructLab Exercises** – Learn how to build and serve fine-tuned models
- **Prompt Engineering** – Master the art of interacting with LLMs
- **AI Guardrails** – Explore methods for securing and validating model output
- **Evals & Benchmarks** – Measure and compare performance of different models

---

## 📌 Notes

- This workshop assumes basic familiarity with containers, CLI tools, and Git.
- If you're running in a sandbox environment or using cloud-based OpenShift, be sure your resources meet the minimum requirements.

---

For questions or contributions, feel free to open a discussion or pull request.
