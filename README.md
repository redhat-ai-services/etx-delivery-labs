# ğŸš€ etx-delivery-labs

Welcome to the **ETX Delivery Labs** â€” a hands-on workshop introducing Artificial Intelligence (AI) concepts and tools within the **Red Hat ecosystem**.

This workshop is designed for developers, architects, and operations teams looking to explore how AI can be integrated with Red Hat technologies such as **OpenShift**, **RHEL AI**, **Podman**, and more.

---

## ğŸ“š What You'll Learn

- The fundamentals of AI/ML practices in enterprise environments
- How to containerize and serve AI models using Podman and OpenShift
- Prompt engineering techniques to get the best from large language models (LLMs)
- Building and evaluating AI pipelines using tools like Ollama, Docling, and HuggingFace
- Guardrails and best practices for responsible AI usage

---

## ğŸ§° Prerequisites

Before you begin, make sure youâ€™ve completed all setup steps outlined in the  
ğŸ‘‰ [Prerequisites Section](workshop/content/prereqs.md)

---

## ğŸ§­ Getting Started

Start the workshop by clicking below:

ğŸ‘‰ [Begin the Workshop](workshop/content/index.md)

---

## ğŸ—ï¸ Structure

The workshop is broken into several self-contained modules:
- **InstructLab Exercises** â€“ Learn how to build and serve fine-tuned models
- **Prompt Engineering** â€“ Master the art of interacting with LLMs
- **AI Guardrails** â€“ Explore methods for securing and validating model output
- **Evals & Benchmarks** â€“ Measure and compare performance of different models

---

## ğŸ“Œ Notes

- This workshop assumes basic familiarity with containers, CLI tools, and Git.
- If you're running in a sandbox environment or using cloud-based OpenShift, be sure your resources meet the minimum requirements.

---

For questions or contributions, feel free to open a discussion or pull request.
